{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5b38e838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6431831440238839\n",
      "0.6350491312552873\n",
      "0.6283268198254136\n",
      "0.6352816703482524\n",
      "0.627029059849045\n",
      "x\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy import stats\n",
    "from sklearn.metrics import accuracy_score,roc_auc_score\n",
    "from sklearn.model_selection import KFold\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "df = pd.read_csv('train.csv')\n",
    "\n",
    "\n",
    "def process_data_1(data):\n",
    "    data.drop(columns=['19'], axis=1, inplace=True)\n",
    "    num_cols = list(map(str.strip,df._get_numeric_data().columns))[:-1]\n",
    "    rows = remove_outlier_stddev(data[num_cols])\n",
    "    data.drop(index=rows, axis=0, inplace=True)\n",
    "    l_col = data['label']\n",
    "    data.drop(columns=['label'], axis=1, inplace=True)\n",
    "    data = pd.get_dummies(data)\n",
    "    return pd.concat([data, l_col], axis=1)\n",
    "\n",
    "\n",
    "def process_data_2(data):\n",
    "    data['2'] = data['2'].apply(lambda x: int(x[:-1]) if type(x) == str else x)  # remove  \"d\" suffix cast as int\n",
    "    data['12'] = data['12'].replace(['y', 'n'], [1, 0])  # change to binary\n",
    "    data['18'] = data['18'].apply(lambda x: int(x[1:]) if type(x) == str else x)  # drop the leading \"a\" in column, cast as int\n",
    "    data['5'] = data['5'].apply(lambda x: float(x) if type(x) == str else x)\n",
    "    data['8'] = data['8'].apply(lambda x: int(x) if type(x) == str else x)\n",
    "    data['14'] = data['14'].fillna(-1)  # fill with -1 where NaN, drop samples\n",
    "    data.drop(columns=['19'], axis=1, inplace=True)\n",
    "    #df.drop(columns=['0', '2', '15', '17', '19', 'label'], axis=1, inplace=True)\n",
    "    data.dropna(inplace=True)\n",
    "    l_col = data['label']\n",
    "    data.drop(columns=['label'], axis=1, inplace=True)\n",
    "    data = pd.get_dummies(data)\n",
    "    # remove outliers\n",
    "    return pd.concat([data, l_col], axis=1)\n",
    "\n",
    "\n",
    "def create_pca(x, n_components):\n",
    "    \"\"\"\n",
    "    create prinicipal component analysis with transformed data\n",
    "    :param x: normalized transformed data set\n",
    "    :param n_components: precentage we want to gurantee variance explained\n",
    "    :return:\n",
    "    \"\"\"\n",
    "    pca = PCA(n_components)\n",
    "    pca.fit(x)\n",
    "    return pca.fit_transform(x)\n",
    "\n",
    "\n",
    "def remove_outlier_stddev(data):\n",
    "    \"\"\"\n",
    "    find row index's containing outliers\n",
    "    :param data: df\n",
    "    :return: list of indexes\n",
    "    \"\"\"\n",
    "    drop_rows = set()\n",
    "    for col in data.columns:\n",
    "        col_mean = data[col].mean()\n",
    "        col_std = data[col].std()\n",
    "        for i, x in enumerate(data[col]):\n",
    "            if abs((x - col_mean) / col_std) > 3:\n",
    "                drop_rows.add(i)\n",
    "    return drop_rows\n",
    "\n",
    "\n",
    "    # return data[data.apply(lambda x: np.abs((x - x.mean()) / x.std()) < 3).all(axis=1)]\n",
    "\n",
    "\n",
    "# def remove_outlier_iqr(data):\n",
    "#     Q3 = np.quantile(data[col], 0.75)\n",
    "#     Q1 = np.quantile(data[col], 0.25)\n",
    "#     IQR = Q3 - Q1\n",
    "#\n",
    "#     lower_range = Q1 - 1.5 * IQR\n",
    "#     upper_range = Q3 + 1.5 * IQR\n",
    "#     outlier_free_list = [x for x in data[col] if (\n",
    "#             (x > lower_range) & (x < upper_range))]\n",
    "#     filtered_data = data.loc[data[col].isin(outlier_free_list)]\n",
    "#\n",
    "#\n",
    "# for i in data.columns:\n",
    "#     removeOutliers(data, i)\n",
    "\n",
    "df = process_data_1(df)\n",
    "label = df['label'].tolist()\n",
    "scaler = MinMaxScaler(feature_range=(0, 1), copy=True)\n",
    "scaler.fit(df)\n",
    "normal_data = pd.DataFrame(scaler.transform(df), index=df.index, columns=df.columns)\n",
    "df = normal_data.apply(lambda x: x.fillna(x.median()), axis=1)\n",
    "\n",
    "pca = PCA(0.95,svd_solver='full')\n",
    "pca.fit(df.loc[:,df.columns!='label'])\n",
    "df = pca.transform(df.loc[:,df.columns!='label'])\n",
    "df=pd.DataFrame(df)\n",
    "df['label']=label\n",
    "# split to train, validation\n",
    "\n",
    "kf = KFold(n_splits=5, random_state=None, shuffle=True)\n",
    "\n",
    "for train_index, validate_index in kf.split(df):\n",
    "    train = df.iloc[train_index].loc[:,df.columns!='label'] # get rows by index list, drop label column\n",
    "    validate = df.iloc[validate_index].loc[:,df.columns!='label']\n",
    "    train_label = np.array(df['label'].iloc[train_index])\n",
    "    validate_label = np.array(df['label'].iloc[validate_index])\n",
    "    knn = KNeighborsClassifier(3)\n",
    "    knn.fit(train, train_label)\n",
    "    predictions = knn.predict(validate)\n",
    "    print(roc_auc_score(validate_label, predictions))\n",
    "# validate_pca = pca.transform(validation.loc[:,train.columns!='label'])\n",
    "\n",
    "# knn = KNeighborsClassifier(3)\n",
    "# knn.fit(train, train_label)\n",
    "# predictions = knn.predict(validation)\n",
    "#\n",
    "\n",
    "\n",
    "print(\"x\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
